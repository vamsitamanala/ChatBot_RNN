{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "<a href='http://www.pieriandata.com'> <img src='../Pierian_Data_Logo.png' /></a>\n",
    "___\n",
    "# Question and Answer Chat Bots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the Data\n",
    "\n",
    "We will be working with the Babi Data Set from Facebook Research.\n",
    "\n",
    "Full Details: https://research.fb.com/downloads/babi/\n",
    "\n",
    "- Jason Weston, Antoine Bordes, Sumit Chopra, Tomas Mikolov, Alexander M. Rush,\n",
    "  \"Towards AI-Complete Question Answering: A Set of Prerequisite Toy Tasks\",\n",
    "  http://arxiv.org/abs/1502.05698\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"train_qa.txt\", \"rb\") as fp:   # Unpickling\n",
    "    train_data =  pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"test_qa.txt\", \"rb\") as fp:   # Unpickling\n",
    "    test_data =  pickle.load(fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring the Format of the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['Mary',\n",
       "  'moved',\n",
       "  'to',\n",
       "  'the',\n",
       "  'bathroom',\n",
       "  '.',\n",
       "  'Sandra',\n",
       "  'journeyed',\n",
       "  'to',\n",
       "  'the',\n",
       "  'bedroom',\n",
       "  '.'],\n",
       " ['Is', 'Sandra', 'in', 'the', 'hallway', '?'],\n",
       " 'no')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Mary moved to the bathroom . Sandra journeyed to the bedroom .'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(train_data[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Is Sandra in the hallway ?'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(train_data[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'no'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0][2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "## Setting up Vocabulary of All Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a set that holds the vocab words\n",
    "vocab = set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = test_data + train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for story, question , answer in all_data:\n",
    "    # In case you don't know what a union of sets is:\n",
    "    # https://www.programiz.com/python-programming/methods/set/union\n",
    "    vocab = vocab.union(set(story))\n",
    "    vocab = vocab.union(set(question))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab.add('no')\n",
    "vocab.add('yes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'.',\n",
       " '?',\n",
       " 'Daniel',\n",
       " 'Is',\n",
       " 'John',\n",
       " 'Mary',\n",
       " 'Sandra',\n",
       " 'apple',\n",
       " 'back',\n",
       " 'bathroom',\n",
       " 'bedroom',\n",
       " 'discarded',\n",
       " 'down',\n",
       " 'dropped',\n",
       " 'football',\n",
       " 'garden',\n",
       " 'got',\n",
       " 'grabbed',\n",
       " 'hallway',\n",
       " 'in',\n",
       " 'journeyed',\n",
       " 'kitchen',\n",
       " 'left',\n",
       " 'milk',\n",
       " 'moved',\n",
       " 'no',\n",
       " 'office',\n",
       " 'picked',\n",
       " 'put',\n",
       " 'the',\n",
       " 'there',\n",
       " 'to',\n",
       " 'took',\n",
       " 'travelled',\n",
       " 'up',\n",
       " 'went',\n",
       " 'yes'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_len = len(vocab) + 1 #we add an extra space to hold a 0 for Keras's pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_story_len = max([len(data[0]) for data in all_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "156"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_story_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_question_len = max([len(data[1]) for data in all_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_question_len"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorizing the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'.',\n",
       " '?',\n",
       " 'Daniel',\n",
       " 'Is',\n",
       " 'John',\n",
       " 'Mary',\n",
       " 'Sandra',\n",
       " 'apple',\n",
       " 'back',\n",
       " 'bathroom',\n",
       " 'bedroom',\n",
       " 'discarded',\n",
       " 'down',\n",
       " 'dropped',\n",
       " 'football',\n",
       " 'garden',\n",
       " 'got',\n",
       " 'grabbed',\n",
       " 'hallway',\n",
       " 'in',\n",
       " 'journeyed',\n",
       " 'kitchen',\n",
       " 'left',\n",
       " 'milk',\n",
       " 'moved',\n",
       " 'no',\n",
       " 'office',\n",
       " 'picked',\n",
       " 'put',\n",
       " 'the',\n",
       " 'there',\n",
       " 'to',\n",
       " 'took',\n",
       " 'travelled',\n",
       " 'up',\n",
       " 'went',\n",
       " 'yes'}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reserve 0 for pad_sequences\n",
    "vocab_size = len(vocab) + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# integer encode sequences of words\n",
    "tokenizer = Tokenizer(filters=[])\n",
    "tokenizer.fit_on_texts(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bedroom': 1,\n",
       " 'down': 2,\n",
       " 'back': 3,\n",
       " 'discarded': 4,\n",
       " 'left': 5,\n",
       " 'dropped': 6,\n",
       " 'apple': 7,\n",
       " 'is': 8,\n",
       " 'milk': 9,\n",
       " 'mary': 10,\n",
       " 'no': 11,\n",
       " 'put': 12,\n",
       " 'kitchen': 13,\n",
       " 'took': 14,\n",
       " 'there': 15,\n",
       " '.': 16,\n",
       " 'garden': 17,\n",
       " 'yes': 18,\n",
       " 'bathroom': 19,\n",
       " 'grabbed': 20,\n",
       " 'picked': 21,\n",
       " '?': 22,\n",
       " 'got': 23,\n",
       " 'the': 24,\n",
       " 'went': 25,\n",
       " 'up': 26,\n",
       " 'sandra': 27,\n",
       " 'in': 28,\n",
       " 'travelled': 29,\n",
       " 'moved': 30,\n",
       " 'john': 31,\n",
       " 'office': 32,\n",
       " 'to': 33,\n",
       " 'hallway': 34,\n",
       " 'football': 35,\n",
       " 'daniel': 36,\n",
       " 'journeyed': 37}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_story_text = []\n",
    "train_question_text = []\n",
    "train_answers = []\n",
    "\n",
    "for story,question,answer in train_data:\n",
    "    train_story_text.append(story)\n",
    "    train_question_text.append(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_story_seq = tokenizer.texts_to_sequences(train_story_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_story_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_story_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# word_index = tokenizer.word_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functionalize Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_stories(data, word_index=tokenizer.word_index, max_story_len=max_story_len,max_question_len=max_question_len):\n",
    "    '''\n",
    "    INPUT: \n",
    "    \n",
    "    data: consisting of Stories,Queries,and Answers\n",
    "    word_index: word index dictionary from tokenizer\n",
    "    max_story_len: the length of the longest story (used for pad_sequences function)\n",
    "    max_question_len: length of the longest question (used for pad_sequences function)\n",
    "\n",
    "\n",
    "    OUTPUT:\n",
    "    \n",
    "    Vectorizes the stories,questions, and answers into padded sequences. We first loop for every story, query , and\n",
    "    answer in the data. Then we convert the raw words to an word index value. Then we append each set to their appropriate\n",
    "    output list. Then once we have converted the words to numbers, we pad the sequences so they are all of equal length.\n",
    "    \n",
    "    Returns this in the form of a tuple (X,Xq,Y) (padded based on max lengths)\n",
    "    '''\n",
    "    \n",
    "    \n",
    "    # X = STORIES\n",
    "    X = []\n",
    "    # Xq = QUERY/QUESTION\n",
    "    Xq = []\n",
    "    # Y = CORRECT ANSWER\n",
    "    Y = []\n",
    "    \n",
    "    \n",
    "    for story, query, answer in data:\n",
    "        \n",
    "        # Grab the word index for every word in story\n",
    "        x = [word_index[word.lower()] for word in story]\n",
    "        # Grab the word index for every word in query\n",
    "        xq = [word_index[word.lower()] for word in query]\n",
    "        \n",
    "        # Grab the Answers (either Yes/No so we don't need to use list comprehension here)\n",
    "        # Index 0 is reserved so we're going to use + 1\n",
    "        y = np.zeros(len(word_index) + 1)\n",
    "        \n",
    "        # Now that y is all zeros and we know its just Yes/No , we can use numpy logic to create this assignment\n",
    "        #\n",
    "        y[word_index[answer]] = 1\n",
    "        \n",
    "        # Append each set of story,query, and answer to their respective holding lists\n",
    "        X.append(x)\n",
    "        Xq.append(xq)\n",
    "        Y.append(y)\n",
    "        \n",
    "    # Finally, pad the sequences based on their max length so the RNN can be trained on uniformly long sequences.\n",
    "        \n",
    "    # RETURN TUPLE FOR UNPACKING\n",
    "    return (pad_sequences(X, maxlen=max_story_len),pad_sequences(Xq, maxlen=max_question_len), np.array(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_train, queries_train, answers_train = vectorize_stories(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_test, queries_test, answers_test = vectorize_stories(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  0,  0, ..., 24,  1, 16],\n",
       "       [ 0,  0,  0, ..., 24, 17, 16],\n",
       "       [ 0,  0,  0, ..., 24, 17, 16],\n",
       "       ...,\n",
       "       [ 0,  0,  0, ..., 24,  7, 16],\n",
       "       [ 0,  0,  0, ..., 24, 17, 16],\n",
       "       [ 0,  0,  0, ...,  7, 15, 16]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 8, 31, 28, 24, 13, 22],\n",
       "       [ 8, 31, 28, 24, 13, 22],\n",
       "       [ 8, 31, 28, 24, 17, 22],\n",
       "       ...,\n",
       "       [ 8, 10, 28, 24,  1, 22],\n",
       "       [ 8, 27, 28, 24, 17, 22],\n",
       "       [ 8, 10, 28, 24, 17, 22]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "queries_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "       503.,   0.,   0.,   0.,   0.,   0.,   0., 497.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(answers_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.word_index['yes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.word_index['no']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential, Model\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers import Input, Activation, Dense, Permute, Dropout\n",
    "from keras.layers import add, dot, concatenate\n",
    "from keras.layers import LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Placeholders for Inputs\n",
    "\n",
    "Recall we technically have two inputs, stories and questions. So we need to use placeholders. `Input()` is used to instantiate a Keras tensor.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_sequence = Input((max_story_len,))\n",
    "question = Input((max_question_len,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Building the Networks\n",
    "\n",
    "To understand why we chose this setup, make sure to read the paper we are using:\n",
    "\n",
    "* Sainbayar Sukhbaatar, Arthur Szlam, Jason Weston, Rob Fergus,\n",
    "  \"End-To-End Memory Networks\",\n",
    "  http://arxiv.org/abs/1503.08895"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoders\n",
    "\n",
    "### Input Encoder m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input gets embedded to a sequence of vectors\n",
    "input_encoder_m = Sequential()\n",
    "input_encoder_m.add(Embedding(input_dim=vocab_size,output_dim=64))\n",
    "input_encoder_m.add(Dropout(0.3))\n",
    "\n",
    "# This encoder will output:\n",
    "# (samples, story_maxlen, embedding_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input Encoder c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embed the input into a sequence of vectors of size query_maxlen\n",
    "input_encoder_c = Sequential()\n",
    "input_encoder_c.add(Embedding(input_dim=vocab_size,output_dim=max_question_len))\n",
    "input_encoder_c.add(Dropout(0.3))\n",
    "# output: (samples, story_maxlen, query_maxlen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embed the question into a sequence of vectors\n",
    "question_encoder = Sequential()\n",
    "question_encoder.add(Embedding(input_dim=vocab_size,\n",
    "                               output_dim=64,\n",
    "                               input_length=max_question_len))\n",
    "question_encoder.add(Dropout(0.3))\n",
    "# output: (samples, query_maxlen, embedding_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encode the Sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode input sequence and questions (which are indices)\n",
    "# to sequences of dense vectors\n",
    "input_encoded_m = input_encoder_m(input_sequence)\n",
    "input_encoded_c = input_encoder_c(input_sequence)\n",
    "question_encoded = question_encoder(question)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Use dot product to compute the match between first input vector seq and the query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shape: `(samples, story_maxlen, query_maxlen)`\n",
    "match = dot([input_encoded_m, question_encoded], axes=(2, 2))\n",
    "match = Activation('softmax')(match)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add this match matrix with the second input vector sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the match matrix with the second input vector sequence\n",
    "response = add([match, input_encoded_c])  # (samples, story_maxlen, query_maxlen)\n",
    "response = Permute((2, 1))(response)  # (samples, query_maxlen, story_maxlen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Concatenate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenate the match matrix with the question vector sequence\n",
    "answer = concatenate([response, question_encoded])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'concatenate_1/concat:0' shape=(None, 6, 220) dtype=float32>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce with RNN (LSTM)\n",
    "answer = LSTM(32)(answer)  # (samples, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regularization with Dropout\n",
    "answer = Dropout(0.5)(answer)\n",
    "answer = Dense(vocab_size)(answer)  # (samples, vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we output a probability distribution over the vocabulary\n",
    "answer = Activation('softmax')(answer)\n",
    "\n",
    "# build the final model\n",
    "model = Model([input_sequence, question], answer)\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 156)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 6)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sequential_1 (Sequential)       multiple             2432        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "sequential_3 (Sequential)       (None, 6, 64)        2432        input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dot_1 (Dot)                     (None, 156, 6)       0           sequential_1[1][0]               \n",
      "                                                                 sequential_3[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 156, 6)       0           dot_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "sequential_2 (Sequential)       multiple             228         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 156, 6)       0           activation_1[0][0]               \n",
      "                                                                 sequential_2[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "permute_1 (Permute)             (None, 6, 156)       0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 6, 220)       0           permute_1[0][0]                  \n",
      "                                                                 sequential_3[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, 32)           32384       concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 32)           0           lstm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 38)           1254        dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 38)           0           dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 38,730\n",
      "Trainable params: 38,730\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Prahasith Kondra\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10000 samples, validate on 1000 samples\n",
      "Epoch 1/120\n",
      "10000/10000 [==============================] - 21s 2ms/step - loss: 0.9387 - accuracy: 0.4978 - val_loss: 0.7007 - val_accuracy: 0.4970\n",
      "Epoch 2/120\n",
      "10000/10000 [==============================] - 15s 2ms/step - loss: 0.7064 - accuracy: 0.5114 - val_loss: 0.6940 - val_accuracy: 0.4970\n",
      "Epoch 3/120\n",
      "10000/10000 [==============================] - 15s 2ms/step - loss: 0.6973 - accuracy: 0.4974 - val_loss: 0.6936 - val_accuracy: 0.4970\n",
      "Epoch 4/120\n",
      "10000/10000 [==============================] - 16s 2ms/step - loss: 0.6953 - accuracy: 0.4903 - val_loss: 0.6933 - val_accuracy: 0.5030\n",
      "Epoch 5/120\n",
      "10000/10000 [==============================] - 15s 2ms/step - loss: 0.6951 - accuracy: 0.4969 - val_loss: 0.6951 - val_accuracy: 0.4970\n",
      "Epoch 6/120\n",
      "10000/10000 [==============================] - 15s 2ms/step - loss: 0.6949 - accuracy: 0.4929 - val_loss: 0.6932 - val_accuracy: 0.5030\n",
      "Epoch 7/120\n",
      "10000/10000 [==============================] - 15s 1ms/step - loss: 0.6942 - accuracy: 0.5058 - val_loss: 0.6937 - val_accuracy: 0.5030\n",
      "Epoch 8/120\n",
      "10000/10000 [==============================] - 15s 2ms/step - loss: 0.6936 - accuracy: 0.5068 - val_loss: 0.6969 - val_accuracy: 0.4970\n",
      "Epoch 9/120\n",
      "10000/10000 [==============================] - 15s 2ms/step - loss: 0.6880 - accuracy: 0.5309 - val_loss: 0.6728 - val_accuracy: 0.5880\n",
      "Epoch 10/120\n",
      "10000/10000 [==============================] - 15s 2ms/step - loss: 0.6081 - accuracy: 0.6786 - val_loss: 0.5170 - val_accuracy: 0.7620\n",
      "Epoch 11/120\n",
      "10000/10000 [==============================] - 15s 2ms/step - loss: 0.4834 - accuracy: 0.7845 - val_loss: 0.4425 - val_accuracy: 0.8280\n",
      "Epoch 12/120\n",
      "10000/10000 [==============================] - 15s 2ms/step - loss: 0.4362 - accuracy: 0.8215 - val_loss: 0.4154 - val_accuracy: 0.8210\n",
      "Epoch 13/120\n",
      "10000/10000 [==============================] - 15s 2ms/step - loss: 0.4076 - accuracy: 0.8357 - val_loss: 0.4044 - val_accuracy: 0.8380\n",
      "Epoch 14/120\n",
      "10000/10000 [==============================] - 15s 2ms/step - loss: 0.3809 - accuracy: 0.8437 - val_loss: 0.3961 - val_accuracy: 0.8200\n",
      "Epoch 15/120\n",
      "10000/10000 [==============================] - 16s 2ms/step - loss: 0.3612 - accuracy: 0.8487 - val_loss: 0.3730 - val_accuracy: 0.8400\n",
      "Epoch 16/120\n",
      "10000/10000 [==============================] - 15s 2ms/step - loss: 0.3552 - accuracy: 0.8495 - val_loss: 0.3668 - val_accuracy: 0.8360\n",
      "Epoch 17/120\n",
      "10000/10000 [==============================] - 15s 2ms/step - loss: 0.3469 - accuracy: 0.8531 - val_loss: 0.3519 - val_accuracy: 0.8460\n",
      "Epoch 18/120\n",
      "10000/10000 [==============================] - 15s 2ms/step - loss: 0.3332 - accuracy: 0.8563 - val_loss: 0.3508 - val_accuracy: 0.8430\n",
      "Epoch 19/120\n",
      "10000/10000 [==============================] - 15s 2ms/step - loss: 0.3269 - accuracy: 0.8570 - val_loss: 0.3533 - val_accuracy: 0.8470\n",
      "Epoch 20/120\n",
      "10000/10000 [==============================] - 15s 2ms/step - loss: 0.3272 - accuracy: 0.8565 - val_loss: 0.3443 - val_accuracy: 0.8460\n",
      "Epoch 21/120\n",
      "10000/10000 [==============================] - 15s 2ms/step - loss: 0.3192 - accuracy: 0.8605 - val_loss: 0.3450 - val_accuracy: 0.8420\n",
      "Epoch 22/120\n",
      "10000/10000 [==============================] - 15s 2ms/step - loss: 0.3152 - accuracy: 0.8581 - val_loss: 0.3431 - val_accuracy: 0.8460\n",
      "Epoch 23/120\n",
      "10000/10000 [==============================] - 15s 2ms/step - loss: 0.3124 - accuracy: 0.8632 - val_loss: 0.3335 - val_accuracy: 0.8370\n",
      "Epoch 24/120\n",
      "10000/10000 [==============================] - 15s 2ms/step - loss: 0.3083 - accuracy: 0.8667 - val_loss: 0.3406 - val_accuracy: 0.8510\n",
      "Epoch 25/120\n",
      "10000/10000 [==============================] - 15s 2ms/step - loss: 0.3076 - accuracy: 0.8623 - val_loss: 0.3545 - val_accuracy: 0.8430\n",
      "Epoch 26/120\n",
      "10000/10000 [==============================] - 15s 2ms/step - loss: 0.3053 - accuracy: 0.8642 - val_loss: 0.3356 - val_accuracy: 0.8540\n",
      "Epoch 27/120\n",
      "10000/10000 [==============================] - 15s 2ms/step - loss: 0.3011 - accuracy: 0.8677 - val_loss: 0.3370 - val_accuracy: 0.8410\n",
      "Epoch 28/120\n",
      "10000/10000 [==============================] - 16s 2ms/step - loss: 0.3008 - accuracy: 0.8665 - val_loss: 0.3516 - val_accuracy: 0.8290\n",
      "Epoch 29/120\n",
      "10000/10000 [==============================] - 15s 2ms/step - loss: 0.3022 - accuracy: 0.8661 - val_loss: 0.3529 - val_accuracy: 0.8400\n",
      "Epoch 30/120\n",
      "10000/10000 [==============================] - 15s 2ms/step - loss: 0.2967 - accuracy: 0.8653 - val_loss: 0.3507 - val_accuracy: 0.8450\n",
      "Epoch 31/120\n",
      "10000/10000 [==============================] - 15s 2ms/step - loss: 0.2972 - accuracy: 0.8684 - val_loss: 0.3470 - val_accuracy: 0.8470\n",
      "Epoch 32/120\n",
      "10000/10000 [==============================] - 16s 2ms/step - loss: 0.2947 - accuracy: 0.8696 - val_loss: 0.3358 - val_accuracy: 0.8380\n",
      "Epoch 33/120\n",
      "10000/10000 [==============================] - 16s 2ms/step - loss: 0.2948 - accuracy: 0.8677 - val_loss: 0.3374 - val_accuracy: 0.8490\n",
      "Epoch 34/120\n",
      "10000/10000 [==============================] - 15s 2ms/step - loss: 0.2941 - accuracy: 0.8671 - val_loss: 0.3307 - val_accuracy: 0.8550\n",
      "Epoch 35/120\n",
      "10000/10000 [==============================] - 15s 1ms/step - loss: 0.2994 - accuracy: 0.8674 - val_loss: 0.3337 - val_accuracy: 0.8500\n",
      "Epoch 36/120\n",
      "10000/10000 [==============================] - 15s 1ms/step - loss: 0.2929 - accuracy: 0.8672 - val_loss: 0.3390 - val_accuracy: 0.8500\n",
      "Epoch 37/120\n",
      "10000/10000 [==============================] - 15s 2ms/step - loss: 0.2924 - accuracy: 0.8682 - val_loss: 0.3390 - val_accuracy: 0.8430\n",
      "Epoch 38/120\n",
      "10000/10000 [==============================] - 15s 2ms/step - loss: 0.2891 - accuracy: 0.8709 - val_loss: 0.3339 - val_accuracy: 0.8490\n",
      "Epoch 39/120\n",
      "10000/10000 [==============================] - 16s 2ms/step - loss: 0.2861 - accuracy: 0.8706 - val_loss: 0.3274 - val_accuracy: 0.8490\n",
      "Epoch 40/120\n",
      "10000/10000 [==============================] - 15s 2ms/step - loss: 0.2887 - accuracy: 0.8687 - val_loss: 0.3364 - val_accuracy: 0.8540\n",
      "Epoch 41/120\n",
      "10000/10000 [==============================] - 15s 2ms/step - loss: 0.2892 - accuracy: 0.8707 - val_loss: 0.3348 - val_accuracy: 0.8520\n",
      "Epoch 42/120\n",
      "10000/10000 [==============================] - 19s 2ms/step - loss: 0.2893 - accuracy: 0.8708 - val_loss: 0.3264 - val_accuracy: 0.8460\n",
      "Epoch 43/120\n",
      "10000/10000 [==============================] - 10815s 1s/step - loss: 0.2882 - accuracy: 0.8740 - val_loss: 0.3379 - val_accuracy: 0.8370\n",
      "Epoch 44/120\n",
      "10000/10000 [==============================] - 15872s 2s/step - loss: 0.2905 - accuracy: 0.8718 - val_loss: 0.3366 - val_accuracy: 0.8550\n",
      "Epoch 45/120\n",
      "10000/10000 [==============================] - 21s 2ms/step - loss: 0.2831 - accuracy: 0.8729 - val_loss: 0.3547 - val_accuracy: 0.8450\n",
      "Epoch 46/120\n",
      "10000/10000 [==============================] - 11s 1ms/step - loss: 0.2839 - accuracy: 0.8729 - val_loss: 0.3681 - val_accuracy: 0.8440\n",
      "Epoch 47/120\n",
      "10000/10000 [==============================] - 12s 1ms/step - loss: 0.2803 - accuracy: 0.8744 - val_loss: 0.3449 - val_accuracy: 0.8450\n",
      "Epoch 48/120\n",
      "10000/10000 [==============================] - 12s 1ms/step - loss: 0.2792 - accuracy: 0.8689 - val_loss: 0.3411 - val_accuracy: 0.8460\n",
      "Epoch 49/120\n",
      "10000/10000 [==============================] - 14s 1ms/step - loss: 0.2796 - accuracy: 0.8744 - val_loss: 0.3508 - val_accuracy: 0.8450\n",
      "Epoch 54/120\n",
      "10000/10000 [==============================] - 14s 1ms/step - loss: 0.2767 - accuracy: 0.8774 - val_loss: 0.3337 - val_accuracy: 0.8460\n",
      "Epoch 55/120\n",
      "10000/10000 [==============================] - 14s 1ms/step - loss: 0.2801 - accuracy: 0.8774 - val_loss: 0.3408 - val_accuracy: 0.8490\n",
      "Epoch 56/120\n",
      "10000/10000 [==============================] - 14s 1ms/step - loss: 0.2712 - accuracy: 0.8763 - val_loss: 0.3527 - val_accuracy: 0.8430\n",
      "Epoch 57/120\n",
      "10000/10000 [==============================] - 14s 1ms/step - loss: 0.2732 - accuracy: 0.8756 - val_loss: 0.3688 - val_accuracy: 0.8500\n",
      "Epoch 58/120\n",
      "10000/10000 [==============================] - 14s 1ms/step - loss: 0.2449 - accuracy: 0.8891 - val_loss: 0.4012 - val_accuracy: 0.8400\n",
      "Epoch 84/120\n",
      "10000/10000 [==============================] - 14s 1ms/step - loss: 0.2433 - accuracy: 0.8913 - val_loss: 0.4137 - val_accuracy: 0.8380\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 85/120\n",
      "10000/10000 [==============================] - 14s 1ms/step - loss: 0.2464 - accuracy: 0.8892 - val_loss: 0.4014 - val_accuracy: 0.8400\n",
      "Epoch 86/120\n",
      "10000/10000 [==============================] - 14s 1ms/step - loss: 0.2430 - accuracy: 0.8911 - val_loss: 0.4234 - val_accuracy: 0.8340\n",
      "Epoch 87/120\n",
      "10000/10000 [==============================] - 14s 1ms/step - loss: 0.2471 - accuracy: 0.8889 - val_loss: 0.3833 - val_accuracy: 0.8380\n",
      "Epoch 88/120\n",
      "10000/10000 [==============================] - 14s 1ms/step - loss: 0.2406 - accuracy: 0.8926 - val_loss: 0.4017 - val_accuracy: 0.8270\n",
      "Epoch 89/120\n",
      "10000/10000 [==============================] - 14s 1ms/step - loss: 0.2345 - accuracy: 0.8954 - val_loss: 0.4185 - val_accuracy: 0.8370\n",
      "Epoch 90/120\n",
      "10000/10000 [==============================] - 14s 1ms/step - loss: 0.2416 - accuracy: 0.8933 - val_loss: 0.3902 - val_accuracy: 0.8390\n",
      "Epoch 91/120\n",
      "10000/10000 [==============================] - 14s 1ms/step - loss: 0.2363 - accuracy: 0.8942 - val_loss: 0.4336 - val_accuracy: 0.8350\n",
      "Epoch 92/120\n",
      "10000/10000 [==============================] - 14s 1ms/step - loss: 0.2401 - accuracy: 0.8945 - val_loss: 0.4000 - val_accuracy: 0.8420\n",
      "Epoch 93/120\n",
      "10000/10000 [==============================] - 14s 1ms/step - loss: 0.2189 - accuracy: 0.9037 - val_loss: 0.4732 - val_accuracy: 0.8270\n",
      "Epoch 103/120\n",
      "10000/10000 [==============================] - 14s 1ms/step - loss: 0.2184 - accuracy: 0.9024 - val_loss: 0.4542 - val_accuracy: 0.8290\n",
      "Epoch 104/120\n",
      "10000/10000 [==============================] - 14s 1ms/step - loss: 0.2233 - accuracy: 0.9018 - val_loss: 0.4417 - val_accuracy: 0.8350\n",
      "Epoch 105/120\n",
      "10000/10000 [==============================] - 14s 1ms/step - loss: 0.2186 - accuracy: 0.9045 - val_loss: 0.4642 - val_accuracy: 0.8320\n",
      "Epoch 106/120\n",
      "10000/10000 [==============================] - 14s 1ms/step - loss: 0.2237 - accuracy: 0.8999 - val_loss: 0.4633 - val_accuracy: 0.8340\n",
      "Epoch 107/120\n",
      "10000/10000 [==============================] - 14s 1ms/step - loss: 0.2154 - accuracy: 0.9055 - val_loss: 0.4440 - val_accuracy: 0.8340\n",
      "Epoch 108/120\n",
      "10000/10000 [==============================] - 14s 1ms/step - loss: 0.2101 - accuracy: 0.9078 - val_loss: 0.4885 - val_accuracy: 0.8270\n",
      "Epoch 109/120\n",
      "10000/10000 [==============================] - 14s 1ms/step - loss: 0.2155 - accuracy: 0.9050 - val_loss: 0.4735 - val_accuracy: 0.8280\n",
      "Epoch 110/120\n",
      "10000/10000 [==============================] - 14s 1ms/step - loss: 0.2243 - accuracy: 0.9035 - val_loss: 0.4651 - val_accuracy: 0.8240\n",
      "Epoch 111/120\n",
      "10000/10000 [==============================] - 14s 1ms/step - loss: 0.2258 - accuracy: 0.9035 - val_loss: 0.4700 - val_accuracy: 0.8300\n",
      "Epoch 112/120\n",
      "10000/10000 [==============================] - 14s 1ms/step - loss: 0.2144 - accuracy: 0.9051 - val_loss: 0.4554 - val_accuracy: 0.8280\n",
      "Epoch 113/120\n",
      "10000/10000 [==============================] - 14s 1ms/step - loss: 0.2121 - accuracy: 0.9034 - val_loss: 0.4721 - val_accuracy: 0.8360\n",
      "Epoch 114/120\n",
      "10000/10000 [==============================] - 14s 1ms/step - loss: 0.2090 - accuracy: 0.9051 - val_loss: 0.4882 - val_accuracy: 0.8230\n",
      "Epoch 115/120\n",
      "10000/10000 [==============================] - 14s 1ms/step - loss: 0.2060 - accuracy: 0.9092 - val_loss: 0.4716 - val_accuracy: 0.8330\n",
      "Epoch 116/120\n",
      "10000/10000 [==============================] - 14s 1ms/step - loss: 0.2074 - accuracy: 0.9094 - val_loss: 0.4609 - val_accuracy: 0.8230\n",
      "Epoch 117/120\n",
      "10000/10000 [==============================] - 14s 1ms/step - loss: 0.2081 - accuracy: 0.9125 - val_loss: 0.4978 - val_accuracy: 0.8270\n",
      "Epoch 118/120\n",
      "10000/10000 [==============================] - 14s 1ms/step - loss: 0.2154 - accuracy: 0.9083 - val_loss: 0.4731 - val_accuracy: 0.8220\n",
      "Epoch 119/120\n",
      "10000/10000 [==============================] - 17s 2ms/step - loss: 0.2074 - accuracy: 0.9091 - val_loss: 0.4703 - val_accuracy: 0.8290\n",
      "Epoch 120/120\n",
      "10000/10000 [==============================] - 16s 2ms/step - loss: 0.2078 - accuracy: 0.9081 - val_loss: 0.4744 - val_accuracy: 0.8340\n"
     ]
    }
   ],
   "source": [
    "# train\n",
    "history = model.fit([inputs_train, queries_train], answers_train,batch_size=32,epochs=120,validation_data=([inputs_test, queries_test], answers_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'chatbot_120_epochs.h5'\n",
    "model.save(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the Model\n",
    "\n",
    "### Plotting Out Training History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['val_loss', 'val_accuracy', 'loss', 'accuracy'])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "print(history.history.keys())\n",
    "# summarize history for accuracy\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating on Given Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(filename)\n",
    "pred_results = model.predict(([inputs_test, queries_test]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Mary',\n",
       " 'got',\n",
       " 'the',\n",
       " 'milk',\n",
       " 'there',\n",
       " '.',\n",
       " 'John',\n",
       " 'moved',\n",
       " 'to',\n",
       " 'the',\n",
       " 'bedroom',\n",
       " '.']"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mary got the milk there . John moved to the bedroom .\n"
     ]
    }
   ],
   "source": [
    "story =' '.join(word for word in test_data[0][0])\n",
    "print(story)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is John in the kitchen ?\n"
     ]
    }
   ],
   "source": [
    "query = ' '.join(word for word in test_data[0][1])\n",
    "print(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Test Answer from Data is: no\n"
     ]
    }
   ],
   "source": [
    "print(\"True Test Answer from Data is:\",test_data[0][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted answer is:  no\n",
      "Probability of certainty was:  0.9999913\n"
     ]
    }
   ],
   "source": [
    "#Generate prediction from model\n",
    "val_max = np.argmax(pred_results[0])\n",
    "\n",
    "for key, val in tokenizer.word_index.items():\n",
    "    if val == val_max:\n",
    "        k = key\n",
    "\n",
    "print(\"Predicted answer is: \", k)\n",
    "print(\"Probability of certainty was: \", pred_results[0][val_max])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Writing Your Own Stories and Questions\n",
    "\n",
    "Remember you can only use words from the existing vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'.',\n",
       " '?',\n",
       " 'Daniel',\n",
       " 'Is',\n",
       " 'John',\n",
       " 'Mary',\n",
       " 'Sandra',\n",
       " 'apple',\n",
       " 'back',\n",
       " 'bathroom',\n",
       " 'bedroom',\n",
       " 'discarded',\n",
       " 'down',\n",
       " 'dropped',\n",
       " 'football',\n",
       " 'garden',\n",
       " 'got',\n",
       " 'grabbed',\n",
       " 'hallway',\n",
       " 'in',\n",
       " 'journeyed',\n",
       " 'kitchen',\n",
       " 'left',\n",
       " 'milk',\n",
       " 'moved',\n",
       " 'no',\n",
       " 'office',\n",
       " 'picked',\n",
       " 'put',\n",
       " 'the',\n",
       " 'there',\n",
       " 'to',\n",
       " 'took',\n",
       " 'travelled',\n",
       " 'up',\n",
       " 'went',\n",
       " 'yes'}"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['John',\n",
       " 'left',\n",
       " 'the',\n",
       " 'kitchen',\n",
       " '.',\n",
       " 'Sandra',\n",
       " 'dropped',\n",
       " 'the',\n",
       " 'football',\n",
       " 'in',\n",
       " 'the',\n",
       " 'garden',\n",
       " '.']"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Note the whitespace of the periods\n",
    "my_story = \"John left the kitchen . Sandra dropped the football in the garden .\"\n",
    "my_story.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_question = \"Is the football in the garden ?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Is', 'the', 'football', 'in', 'the', 'garden', '?']"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_question.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "mydata = [(my_story.split(),my_question.split(),'yes')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_story,my_ques,my_ans = vectorize_stories(mydata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_results = model.predict(([ my_story, my_ques]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted answer is:  yes\n",
      "Probability of certainty was:  0.99993443\n"
     ]
    }
   ],
   "source": [
    "#Generate prediction from model\n",
    "val_max = np.argmax(pred_results[0])\n",
    "\n",
    "for key, val in tokenizer.word_index.items():\n",
    "    if val == val_max:\n",
    "        k = key\n",
    "\n",
    "print(\"Predicted answer is: \", k)\n",
    "print(\"Probability of certainty was: \", pred_results[0][val_max])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Great Job!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
